{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured Output with Pydantic Models\n",
    "\n",
    "This notebook demonstrates how to get structured, validated data from agent responses using Pydantic models instead of free-form text.\n",
    "\n",
    "## Key Concepts\n",
    "- **Pydantic Models**: Define expected data structure\n",
    "- **Type Validation**: Automatic validation and error checking\n",
    "- **Structured Responses**: Guaranteed data format for downstream processing\n",
    "- **Database Integration**: Easy integration with databases and APIs\n",
    "\n",
    "## Benefits\n",
    "- **Guaranteed Format**: Consistent output regardless of model variations\n",
    "- **Type Safety**: Validation prevents data errors\n",
    "- **Easy Processing**: Direct use in applications without parsing\n",
    "- **Documentation**: Self-documenting data structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Make sure you have the required packages installed:\n",
    "\n",
    "```bash\n",
    "pip install langchain langchain-community langchain-core langgraph pydantic\n",
    "ollama pull qwen3\n",
    "ollama serve\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from typing import List, Optional, Union\n",
    "from datetime import datetime\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.agents import create_agent\n",
    "import tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Structured Output Example\n",
    "\n",
    "Let's start with a simple contact information extraction example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Basic Structured Output Example ===\")\n",
    "\n",
    "# Define the structure we want the agent to return\n",
    "class ContactInfo(BaseModel):\n",
    "    \"\"\"Contact information structure.\"\"\"\n",
    "    name: str = Field(description=\"Full name of the person\")\n",
    "    email: str = Field(description=\"Email address\")\n",
    "    phone: str = Field(description=\"Phone number\")\n",
    "    company: str = Field(default=\"Unknown\", description=\"Company name (optional)\")\n",
    "    \n",
    "    @validator('email')\n",
    "    def validate_email(cls, v):\n",
    "        \"\"\"Basic email validation.\"\"\"\n",
    "        if '@' not in v:\n",
    "            raise ValueError('Invalid email format')\n",
    "        return v\n",
    "\n",
    "# Display the model structure\n",
    "print(\"âœ“ ContactInfo model defined with fields:\")\n",
    "for field_name, field_info in ContactInfo.__fields__.items():\n",
    "    required = \"(required)\" if field_info.is_required() else \"(optional)\"\n",
    "    print(f\"  - {field_name}: {field_info.type_} {required}\")\n",
    "    if field_info.field_info.description:\n",
    "        print(f\"    Description: {field_info.field_info.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Agent with Structured Output\n",
    "\n",
    "Note: In this demo, we'll show the concept. Full structured output integration depends on your LangChain version and model support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and agent\n",
    "model = ChatOllama(model=\"qwen3\")\n",
    "\n",
    "# Create agent with structured output requirement (conceptual)\n",
    "# Note: Actual implementation may vary based on LangChain version\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=[tools.extract_contact],\n",
    "    # response_format=ContactInfo  # This would force structured output in some implementations\n",
    ")\n",
    "\n",
    "print(\"âœ“ Agent created for contact information extraction\")\n",
    "print(\"  The agent will extract contact information and format it consistently\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Contact Information Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with contact information\n",
    "contact_text = \"Extract contact info from: John Doe, john@example.com, (555) 123-4567, works at TechCorp\"\n",
    "\n",
    "print(f\"Input text: {contact_text}\")\n",
    "print(\"\\n=== Agent Processing ===\")\n",
    "\n",
    "try:\n",
    "    result = agent.invoke({\n",
    "        \"messages\": contact_text\n",
    "    })\n",
    "    \n",
    "    print(f\"âœ“ Agent response: {result['messages'][-1].content}\")\n",
    "    \n",
    "    # In a real implementation, you would extract structured data here\n",
    "    print(\"\\n=== Simulated Structured Output ===\")\n",
    "    \n",
    "    # Simulate extracting structured data\n",
    "    structured_data = ContactInfo(\n",
    "        name=\"John Doe\",\n",
    "        email=\"john@example.com\",\n",
    "        phone=\"(555) 123-4567\",\n",
    "        company=\"TechCorp\"\n",
    "    )\n",
    "    \n",
    "    print(f\"Structured data: {structured_data}\")\n",
    "    print(f\"\\nAs JSON: {structured_data.json(indent=2)}\")\n",
    "    print(f\"\\nAs dict: {structured_data.dict()}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ In production, you'd get a ContactInfo object with guaranteed fields\")\n",
    "print(\"   This enables direct database insertion, API calls, etc.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Structured Models\n",
    "\n",
    "Let's create more complex models for different use cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Advanced Structured Models ===\")\n",
    "\n",
    "# Research Paper Analysis Model\n",
    "class ResearchPaper(BaseModel):\n",
    "    \"\"\"Structure for research paper analysis.\"\"\"\n",
    "    title: str = Field(description=\"Paper title\")\n",
    "    authors: List[str] = Field(description=\"List of author names\")\n",
    "    abstract: str = Field(description=\"Paper abstract\")\n",
    "    keywords: List[str] = Field(description=\"Key topics and terms\")\n",
    "    methodology: Optional[str] = Field(None, description=\"Research methodology used\")\n",
    "    findings: List[str] = Field(description=\"Key findings and results\")\n",
    "    publication_year: Optional[int] = Field(None, description=\"Year of publication\")\n",
    "    \n",
    "    @validator('publication_year')\n",
    "    def validate_year(cls, v):\n",
    "        if v is not None and (v < 1900 or v > datetime.now().year):\n",
    "            raise ValueError('Invalid publication year')\n",
    "        return v\n",
    "\n",
    "# Business Analysis Model\n",
    "class BusinessAnalysis(BaseModel):\n",
    "    \"\"\"Structure for business analysis results.\"\"\"\n",
    "    company_name: str = Field(description=\"Company name\")\n",
    "    industry: str = Field(description=\"Industry sector\")\n",
    "    strengths: List[str] = Field(description=\"Company strengths\")\n",
    "    weaknesses: List[str] = Field(description=\"Areas for improvement\")\n",
    "    opportunities: List[str] = Field(description=\"Market opportunities\")\n",
    "    threats: List[str] = Field(description=\"Potential threats\")\n",
    "    financial_metrics: Optional[dict] = Field(None, description=\"Key financial indicators\")\n",
    "    recommendation: str = Field(description=\"Overall recommendation\")\n",
    "    confidence_score: float = Field(ge=0.0, le=1.0, description=\"Analysis confidence (0-1)\")\n",
    "\n",
    "# Technical Documentation Model\n",
    "class TechnicalDoc(BaseModel):\n",
    "    \"\"\"Structure for technical documentation.\"\"\"\n",
    "    title: str = Field(description=\"Documentation title\")\n",
    "    overview: str = Field(description=\"High-level overview\")\n",
    "    requirements: List[str] = Field(description=\"System requirements\")\n",
    "    installation_steps: List[str] = Field(description=\"Step-by-step installation\")\n",
    "    api_endpoints: Optional[List[dict]] = Field(None, description=\"API endpoint details\")\n",
    "    examples: List[dict] = Field(description=\"Code examples\")\n",
    "    troubleshooting: List[dict] = Field(description=\"Common issues and solutions\")\n",
    "    last_updated: datetime = Field(default_factory=datetime.now, description=\"Last update timestamp\")\n",
    "\n",
    "print(\"âœ“ Advanced models defined:\")\n",
    "print(\"  - ResearchPaper: For academic paper analysis\")\n",
    "print(\"  - BusinessAnalysis: For SWOT analysis and business insights\")\n",
    "print(\"  - TechnicalDoc: For software documentation generation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrating Model Usage\n",
    "\n",
    "Let's show how these models work with sample data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Model Usage Examples ===\")\n",
    "\n",
    "# Example 1: Research Paper\n",
    "print(\"\\n--- Research Paper Example ---\")\n",
    "try:\n",
    "    paper = ResearchPaper(\n",
    "        title=\"Deep Learning for Natural Language Processing\",\n",
    "        authors=[\"Alice Smith\", \"Bob Johnson\", \"Carol Wilson\"],\n",
    "        abstract=\"This paper explores the application of deep learning techniques...\",\n",
    "        keywords=[\"deep learning\", \"NLP\", \"neural networks\", \"transformers\"],\n",
    "        methodology=\"Experimental study using transformer architectures\",\n",
    "        findings=[\n",
    "            \"Transformer models outperform RNNs on most NLP tasks\",\n",
    "            \"Attention mechanisms are crucial for long-range dependencies\",\n",
    "            \"Pre-training on large corpora improves downstream performance\"\n",
    "        ],\n",
    "        publication_year=2023\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ“ Research paper created: {paper.title}\")\n",
    "    print(f\"  Authors: {', '.join(paper.authors)}\")\n",
    "    print(f\"  Keywords: {', '.join(paper.keywords)}\")\n",
    "    print(f\"  Findings: {len(paper.findings)} key results\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error creating research paper: {e}\")\n",
    "\n",
    "# Example 2: Business Analysis\n",
    "print(\"\\n--- Business Analysis Example ---\")\n",
    "try:\n",
    "    analysis = BusinessAnalysis(\n",
    "        company_name=\"TechStart Inc.\",\n",
    "        industry=\"Software Technology\",\n",
    "        strengths=[\n",
    "            \"Strong technical team\",\n",
    "            \"Innovative product\",\n",
    "            \"Growing market demand\"\n",
    "        ],\n",
    "        weaknesses=[\n",
    "            \"Limited marketing budget\",\n",
    "            \"Small customer base\"\n",
    "        ],\n",
    "        opportunities=[\n",
    "            \"Expanding to international markets\",\n",
    "            \"Partnership with larger companies\"\n",
    "        ],\n",
    "        threats=[\n",
    "            \"Competition from established players\",\n",
    "            \"Economic downturn\"\n",
    "        ],\n",
    "        financial_metrics={\n",
    "            \"revenue_growth\": \"150% YoY\",\n",
    "            \"burn_rate\": \"$50k/month\",\n",
    "            \"runway\": \"18 months\"\n",
    "        },\n",
    "        recommendation=\"Focus on customer acquisition and seek Series A funding\",\n",
    "        confidence_score=0.85\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ“ Business analysis created for: {analysis.company_name}\")\n",
    "    print(f\"  Industry: {analysis.industry}\")\n",
    "    print(f\"  Confidence: {analysis.confidence_score:.1%}\")\n",
    "    print(f\"  Recommendation: {analysis.recommendation}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error creating business analysis: {e}\")\n",
    "\n",
    "# Example 3: Technical Documentation\n",
    "print(\"\\n--- Technical Documentation Example ---\")\n",
    "try:\n",
    "    tech_doc = TechnicalDoc(\n",
    "        title=\"API Gateway Setup Guide\",\n",
    "        overview=\"This guide covers the setup and configuration of our API gateway service\",\n",
    "        requirements=[\n",
    "            \"Docker 20.10+\",\n",
    "            \"Node.js 16+\",\n",
    "            \"PostgreSQL 13+\"\n",
    "        ],\n",
    "        installation_steps=[\n",
    "            \"Clone the repository\",\n",
    "            \"Install dependencies with npm install\",\n",
    "            \"Configure environment variables\",\n",
    "            \"Run docker-compose up\"\n",
    "        ],\n",
    "        api_endpoints=[\n",
    "            {\"method\": \"GET\", \"path\": \"/api/health\", \"description\": \"Health check endpoint\"},\n",
    "            {\"method\": \"POST\", \"path\": \"/api/auth\", \"description\": \"Authentication endpoint\"}\n",
    "        ],\n",
    "        examples=[\n",
    "            {\n",
    "                \"language\": \"curl\",\n",
    "                \"code\": \"curl -X GET http://localhost:3000/api/health\",\n",
    "                \"description\": \"Check API health\"\n",
    "            }\n",
    "        ],\n",
    "        troubleshooting=[\n",
    "            {\n",
    "                \"issue\": \"Port already in use\",\n",
    "                \"solution\": \"Change port in docker-compose.yml or stop conflicting service\"\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ“ Technical documentation created: {tech_doc.title}\")\n",
    "    print(f\"  Requirements: {len(tech_doc.requirements)} items\")\n",
    "    print(f\"  Installation steps: {len(tech_doc.installation_steps)} steps\")\n",
    "    print(f\"  API endpoints: {len(tech_doc.api_endpoints or [])} endpoints\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error creating technical documentation: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Validation and Error Handling\n",
    "\n",
    "Let's demonstrate Pydantic's validation capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Data Validation Examples ===\")\n",
    "\n",
    "# Test validation with invalid data\n",
    "print(\"\\n--- Testing Email Validation ---\")\n",
    "try:\n",
    "    # This should fail due to invalid email\n",
    "    invalid_contact = ContactInfo(\n",
    "        name=\"Jane Doe\",\n",
    "        email=\"invalid-email\",  # No @ symbol\n",
    "        phone=\"555-1234\"\n",
    "    )\n",
    "    print(\"âœ— Validation should have failed!\")\n",
    "except Exception as e:\n",
    "    print(f\"âœ“ Validation correctly failed: {e}\")\n",
    "\n",
    "# Test with valid email\n",
    "try:\n",
    "    valid_contact = ContactInfo(\n",
    "        name=\"Jane Doe\",\n",
    "        email=\"jane@example.com\",\n",
    "        phone=\"555-1234\"\n",
    "    )\n",
    "    print(f\"âœ“ Valid contact created: {valid_contact.name}\")\n",
    "except Exception as e:\n",
    "    print(f\"âœ— Unexpected error: {e}\")\n",
    "\n",
    "# Test confidence score validation\n",
    "print(\"\\n--- Testing Confidence Score Validation ---\")\n",
    "try:\n",
    "    # This should fail due to confidence score > 1.0\n",
    "    invalid_analysis = BusinessAnalysis(\n",
    "        company_name=\"Test Corp\",\n",
    "        industry=\"Testing\",\n",
    "        strengths=[\"Good tests\"],\n",
    "        weaknesses=[\"Needs improvement\"],\n",
    "        opportunities=[\"Market expansion\"],\n",
    "        threats=[\"Competition\"],\n",
    "        recommendation=\"Test more\",\n",
    "        confidence_score=1.5  # Invalid: > 1.0\n",
    "    )\n",
    "    print(\"âœ— Validation should have failed!\")\n",
    "except Exception as e:\n",
    "    print(f\"âœ“ Validation correctly failed: {e}\")\n",
    "\n",
    "# Test publication year validation\n",
    "print(\"\\n--- Testing Publication Year Validation ---\")\n",
    "try:\n",
    "    # This should fail due to invalid year\n",
    "    invalid_paper = ResearchPaper(\n",
    "        title=\"Time Travel Research\",\n",
    "        authors=[\"Future Scientist\"],\n",
    "        abstract=\"Research from the future\",\n",
    "        keywords=[\"time\", \"travel\"],\n",
    "        findings=[\"Time travel is possible\"],\n",
    "        publication_year=2050  # Invalid: future year\n",
    "    )\n",
    "    print(\"âœ— Validation should have failed!\")\n",
    "except Exception as e:\n",
    "    print(f\"âœ“ Validation correctly failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Integration Patterns\n",
    "\n",
    "Let's show how to integrate structured output with real applications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Practical Integration Patterns ===\")\n",
    "\n",
    "# Pattern 1: Database Integration\n",
    "class DatabaseIntegration:\n",
    "    \"\"\"Simulate database operations with structured data.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.contacts = []  # Simulate database table\n",
    "        self.papers = []\n",
    "        self.analyses = []\n",
    "    \n",
    "    def save_contact(self, contact: ContactInfo) -> str:\n",
    "        \"\"\"Save contact to database.\"\"\"\n",
    "        contact_dict = contact.dict()\n",
    "        contact_dict['id'] = len(self.contacts) + 1\n",
    "        self.contacts.append(contact_dict)\n",
    "        return f\"Contact saved with ID: {contact_dict['id']}\"\n",
    "    \n",
    "    def save_paper(self, paper: ResearchPaper) -> str:\n",
    "        \"\"\"Save research paper to database.\"\"\"\n",
    "        paper_dict = paper.dict()\n",
    "        paper_dict['id'] = len(self.papers) + 1\n",
    "        self.papers.append(paper_dict)\n",
    "        return f\"Paper saved with ID: {paper_dict['id']}\"\n",
    "    \n",
    "    def get_statistics(self) -> dict:\n",
    "        \"\"\"Get database statistics.\"\"\"\n",
    "        return {\n",
    "            \"contacts\": len(self.contacts),\n",
    "            \"papers\": len(self.papers),\n",
    "            \"analyses\": len(self.analyses)\n",
    "        }\n",
    "\n",
    "# Pattern 2: API Response Format\n",
    "class APIResponse(BaseModel):\n",
    "    \"\"\"Standard API response format.\"\"\"\n",
    "    success: bool = Field(description=\"Operation success status\")\n",
    "    message: str = Field(description=\"Response message\")\n",
    "    data: Optional[Union[ContactInfo, ResearchPaper, BusinessAnalysis]] = Field(None, description=\"Response data\")\n",
    "    errors: Optional[List[str]] = Field(None, description=\"Error messages\")\n",
    "    timestamp: datetime = Field(default_factory=datetime.now, description=\"Response timestamp\")\n",
    "\n",
    "# Pattern 3: Batch Processing\n",
    "class BatchProcessor:\n",
    "    \"\"\"Process multiple structured objects.\"\"\"\n",
    "    \n",
    "    def process_contacts(self, contacts: List[ContactInfo]) -> dict:\n",
    "        \"\"\"Process a batch of contacts.\"\"\"\n",
    "        processed = 0\n",
    "        errors = []\n",
    "        \n",
    "        for i, contact in enumerate(contacts):\n",
    "            try:\n",
    "                # Simulate processing\n",
    "                if contact.email and '@' in contact.email:\n",
    "                    processed += 1\n",
    "                else:\n",
    "                    errors.append(f\"Contact {i+1}: Invalid email\")\n",
    "            except Exception as e:\n",
    "                errors.append(f\"Contact {i+1}: {str(e)}\")\n",
    "        \n",
    "        return {\n",
    "            \"total\": len(contacts),\n",
    "            \"processed\": processed,\n",
    "            \"errors\": errors\n",
    "        }\n",
    "\n",
    "print(\"âœ“ Integration patterns defined:\")\n",
    "print(\"  - DatabaseIntegration: Save structured data to database\")\n",
    "print(\"  - APIResponse: Standard API response format\")\n",
    "print(\"  - BatchProcessor: Handle multiple structured objects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Integration Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Testing Integration Patterns ===\")\n",
    "\n",
    "# Test database integration\n",
    "print(\"\\n--- Database Integration Test ---\")\n",
    "db = DatabaseIntegration()\n",
    "\n",
    "# Create and save some contacts\n",
    "contacts = [\n",
    "    ContactInfo(name=\"Alice Smith\", email=\"alice@example.com\", phone=\"555-0001\", company=\"TechCorp\"),\n",
    "    ContactInfo(name=\"Bob Jones\", email=\"bob@example.com\", phone=\"555-0002\"),\n",
    "    ContactInfo(name=\"Carol Wilson\", email=\"carol@research.edu\", phone=\"555-0003\", company=\"University\")\n",
    "]\n",
    "\n",
    "for contact in contacts:\n",
    "    result = db.save_contact(contact)\n",
    "    print(f\"  {result}\")\n",
    "\n",
    "print(f\"\\nDatabase statistics: {db.get_statistics()}\")\n",
    "\n",
    "# Test API response format\n",
    "print(\"\\n--- API Response Format Test ---\")\n",
    "try:\n",
    "    # Success response\n",
    "    success_response = APIResponse(\n",
    "        success=True,\n",
    "        message=\"Contact retrieved successfully\",\n",
    "        data=contacts[0]\n",
    "    )\n",
    "    print(f\"âœ“ Success response created\")\n",
    "    print(f\"  Message: {success_response.message}\")\n",
    "    print(f\"  Data type: {type(success_response.data).__name__}\")\n",
    "    \n",
    "    # Error response\n",
    "    error_response = APIResponse(\n",
    "        success=False,\n",
    "        message=\"Validation failed\",\n",
    "        errors=[\"Invalid email format\", \"Missing required field\"]\n",
    "    )\n",
    "    print(f\"\\nâœ“ Error response created\")\n",
    "    print(f\"  Errors: {len(error_response.errors)} items\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error creating API response: {e}\")\n",
    "\n",
    "# Test batch processing\n",
    "print(\"\\n--- Batch Processing Test ---\")\n",
    "processor = BatchProcessor()\n",
    "\n",
    "# Mix of valid and invalid contacts\n",
    "batch_contacts = [\n",
    "    ContactInfo(name=\"Valid User\", email=\"valid@example.com\", phone=\"555-1111\"),\n",
    "    ContactInfo(name=\"Another Valid\", email=\"another@example.com\", phone=\"555-2222\"),\n",
    "]\n",
    "\n",
    "batch_result = processor.process_contacts(batch_contacts)\n",
    "print(f\"âœ“ Batch processing completed:\")\n",
    "print(f\"  Total: {batch_result['total']}\")\n",
    "print(f\"  Processed: {batch_result['processed']}\")\n",
    "print(f\"  Errors: {len(batch_result['errors'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Pydantic Features\n",
    "\n",
    "Let's explore some advanced Pydantic features useful for agent outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Advanced Pydantic Features ===\")\n",
    "\n",
    "from enum import Enum\n",
    "from typing import Dict, Any\n",
    "from pydantic import root_validator, constr, conint, conlist\n",
    "\n",
    "# Enums for controlled values\n",
    "class Priority(str, Enum):\n",
    "    LOW = \"low\"\n",
    "    MEDIUM = \"medium\"\n",
    "    HIGH = \"high\"\n",
    "    CRITICAL = \"critical\"\n",
    "\n",
    "class Status(str, Enum):\n",
    "    PENDING = \"pending\"\n",
    "    IN_PROGRESS = \"in_progress\"\n",
    "    COMPLETED = \"completed\"\n",
    "    CANCELLED = \"cancelled\"\n",
    "\n",
    "# Advanced model with constraints and validation\n",
    "class TaskAnalysis(BaseModel):\n",
    "    \"\"\"Advanced task analysis with constraints.\"\"\"\n",
    "    \n",
    "    # Constrained strings\n",
    "    title: constr(min_length=5, max_length=100) = Field(description=\"Task title\")\n",
    "    description: constr(min_length=10) = Field(description=\"Detailed description\")\n",
    "    \n",
    "    # Enums for controlled values\n",
    "    priority: Priority = Field(description=\"Task priority level\")\n",
    "    status: Status = Field(default=Status.PENDING, description=\"Current status\")\n",
    "    \n",
    "    # Constrained numbers\n",
    "    estimated_hours: conint(ge=1, le=1000) = Field(description=\"Estimated hours (1-1000)\")\n",
    "    completion_percentage: conint(ge=0, le=100) = Field(default=0, description=\"Completion (0-100%)\")\n",
    "    \n",
    "    # Constrained lists\n",
    "    tags: conlist(str, min_items=1, max_items=10) = Field(description=\"1-10 tags\")\n",
    "    dependencies: Optional[List[str]] = Field(default=[], description=\"Task dependencies\")\n",
    "    \n",
    "    # Complex nested data\n",
    "    metadata: Optional[Dict[str, Any]] = Field(default={}, description=\"Additional metadata\")\n",
    "    \n",
    "    # Custom validation\n",
    "    @root_validator\n",
    "    def validate_status_completion(cls, values):\n",
    "        \"\"\"Ensure completion percentage matches status.\"\"\"\n",
    "        status = values.get('status')\n",
    "        completion = values.get('completion_percentage', 0)\n",
    "        \n",
    "        if status == Status.COMPLETED and completion < 100:\n",
    "            raise ValueError('Completed tasks must have 100% completion')\n",
    "        \n",
    "        if status == Status.PENDING and completion > 0:\n",
    "            raise ValueError('Pending tasks should have 0% completion')\n",
    "        \n",
    "        return values\n",
    "    \n",
    "    @validator('tags')\n",
    "    def validate_tags(cls, v):\n",
    "        \"\"\"Ensure tags are lowercase and unique.\"\"\"\n",
    "        cleaned_tags = [tag.lower().strip() for tag in v]\n",
    "        if len(cleaned_tags) != len(set(cleaned_tags)):\n",
    "            raise ValueError('Tags must be unique')\n",
    "        return cleaned_tags\n",
    "\n",
    "print(\"âœ“ Advanced TaskAnalysis model defined with:\")\n",
    "print(\"  - Constrained string lengths\")\n",
    "print(\"  - Enum-based controlled values\")\n",
    "print(\"  - Numeric constraints\")\n",
    "print(\"  - List size constraints\")\n",
    "print(\"  - Custom cross-field validation\")\n",
    "print(\"  - Tag normalization and uniqueness\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Advanced Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Testing Advanced Features ===\")\n",
    "\n",
    "# Test valid task\n",
    "print(\"\\n--- Valid Task Creation ---\")\n",
    "try:\n",
    "    valid_task = TaskAnalysis(\n",
    "        title=\"Implement user authentication\",\n",
    "        description=\"Create a secure authentication system with JWT tokens and password hashing\",\n",
    "        priority=Priority.HIGH,\n",
    "        status=Status.IN_PROGRESS,\n",
    "        estimated_hours=25,\n",
    "        completion_percentage=60,\n",
    "        tags=[\"authentication\", \"security\", \"backend\", \"jwt\"],\n",
    "        dependencies=[\"database-setup\", \"user-model\"],\n",
    "        metadata={\n",
    "            \"assigned_to\": \"senior-dev\",\n",
    "            \"sprint\": \"2024-Q1\",\n",
    "            \"complexity\": \"medium\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ“ Valid task created: {valid_task.title}\")\n",
    "    print(f\"  Priority: {valid_task.priority.value}\")\n",
    "    print(f\"  Status: {valid_task.status.value}\")\n",
    "    print(f\"  Progress: {valid_task.completion_percentage}%\")\n",
    "    print(f\"  Tags: {', '.join(valid_task.tags)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âœ— Unexpected error: {e}\")\n",
    "\n",
    "# Test validation errors\n",
    "print(\"\\n--- Testing Validation Errors ---\")\n",
    "\n",
    "# Test title too short\n",
    "try:\n",
    "    TaskAnalysis(\n",
    "        title=\"Hi\",  # Too short\n",
    "        description=\"This should fail due to short title\",\n",
    "        priority=Priority.LOW,\n",
    "        estimated_hours=5,\n",
    "        tags=[\"test\"]\n",
    "    )\n",
    "    print(\"âœ— Should have failed: title too short\")\n",
    "except Exception as e:\n",
    "    print(f\"âœ“ Correctly failed: {e}\")\n",
    "\n",
    "# Test status/completion mismatch\n",
    "try:\n",
    "    TaskAnalysis(\n",
    "        title=\"Test completed task\",\n",
    "        description=\"This should fail due to completion mismatch\",\n",
    "        priority=Priority.LOW,\n",
    "        status=Status.COMPLETED,\n",
    "        completion_percentage=50,  # Should be 100 for completed\n",
    "        estimated_hours=5,\n",
    "        tags=[\"test\"]\n",
    "    )\n",
    "    print(\"âœ— Should have failed: completion percentage mismatch\")\n",
    "except Exception as e:\n",
    "    print(f\"âœ“ Correctly failed: {e}\")\n",
    "\n",
    "# Test duplicate tags\n",
    "try:\n",
    "    TaskAnalysis(\n",
    "        title=\"Test duplicate tags\",\n",
    "        description=\"This should fail due to duplicate tags\",\n",
    "        priority=Priority.LOW,\n",
    "        estimated_hours=5,\n",
    "        tags=[\"test\", \"TEST\", \"test\"]  # Duplicates after normalization\n",
    "    )\n",
    "    print(\"âœ— Should have failed: duplicate tags\")\n",
    "except Exception as e:\n",
    "    print(f\"âœ“ Correctly failed: {e}\")\n",
    "\n",
    "# Test tag normalization (should work)\n",
    "try:\n",
    "    normalized_task = TaskAnalysis(\n",
    "        title=\"Test tag normalization\",\n",
    "        description=\"This should work with tag normalization\",\n",
    "        priority=Priority.LOW,\n",
    "        estimated_hours=5,\n",
    "        tags=[\"  Frontend  \", \"REACT\", \"Javascript\"]  # Will be normalized\n",
    "    )\n",
    "    print(f\"âœ“ Tag normalization works: {normalized_task.tags}\")\n",
    "except Exception as e:\n",
    "    print(f\"âœ— Unexpected error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export and Serialization\n",
    "\n",
    "Pydantic models can be easily exported to various formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Export and Serialization ===\")\n",
    "\n",
    "# Create a sample task for export\n",
    "sample_task = TaskAnalysis(\n",
    "    title=\"Export demonstration task\",\n",
    "    description=\"This task demonstrates various export formats available in Pydantic\",\n",
    "    priority=Priority.MEDIUM,\n",
    "    status=Status.IN_PROGRESS,\n",
    "    estimated_hours=8,\n",
    "    completion_percentage=25,\n",
    "    tags=[\"demo\", \"export\", \"pydantic\"],\n",
    "    dependencies=[\"setup-environment\"],\n",
    "    metadata={\n",
    "        \"created_by\": \"demo_system\",\n",
    "        \"project\": \"structured_output_demo\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"\\n--- JSON Export ---\")\n",
    "json_output = sample_task.json(indent=2)\n",
    "print(json_output)\n",
    "\n",
    "print(\"\\n--- Dictionary Export ---\")\n",
    "dict_output = sample_task.dict()\n",
    "print(f\"Dictionary with {len(dict_output)} fields\")\n",
    "for key, value in dict_output.items():\n",
    "    print(f\"  {key}: {type(value).__name__} = {value}\")\n",
    "\n",
    "print(\"\\n--- Selective Export ---\")\n",
    "# Export only specific fields\n",
    "summary_dict = sample_task.dict(include={'title', 'priority', 'status', 'completion_percentage'})\n",
    "print(f\"Summary: {summary_dict}\")\n",
    "\n",
    "# Exclude sensitive data\n",
    "public_dict = sample_task.dict(exclude={'metadata'})\n",
    "print(f\"\\nPublic data (excluding metadata): {len(public_dict)} fields\")\n",
    "\n",
    "print(\"\\n--- Schema Export ---\")\n",
    "# Get the JSON schema\n",
    "schema = TaskAnalysis.schema()\n",
    "print(f\"Schema has {len(schema['properties'])} properties\")\n",
    "print(\"Required fields:\", schema.get('required', []))\n",
    "\n",
    "# Show just the properties\n",
    "print(\"\\nField definitions:\")\n",
    "for field_name, field_schema in schema['properties'].items():\n",
    "    field_type = field_schema.get('type', 'object')\n",
    "    description = field_schema.get('description', 'No description')\n",
    "    print(f\"  {field_name}: {field_type} - {description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices Summary\n",
    "\n",
    "### Model Design Principles\n",
    "\n",
    "1. **Clear Field Names**: Use descriptive, unambiguous field names\n",
    "2. **Comprehensive Descriptions**: Add Field descriptions for documentation\n",
    "3. **Appropriate Defaults**: Provide sensible default values\n",
    "4. **Type Constraints**: Use constrained types (constr, conint, etc.)\n",
    "5. **Validation Logic**: Add custom validators for business rules\n",
    "\n",
    "### Validation Best Practices\n",
    "\n",
    "1. **Input Sanitization**: Clean and normalize input data\n",
    "2. **Cross-Field Validation**: Use root_validator for complex rules\n",
    "3. **Meaningful Errors**: Provide clear error messages\n",
    "4. **Performance**: Keep validation logic efficient\n",
    "5. **Security**: Validate against injection attacks\n",
    "\n",
    "### Integration Patterns\n",
    "\n",
    "1. **Database Models**: Map Pydantic models to database schemas\n",
    "2. **API Responses**: Use structured responses for consistency\n",
    "3. **Batch Processing**: Handle multiple objects efficiently\n",
    "4. **Error Handling**: Graceful degradation with validation errors\n",
    "5. **Documentation**: Auto-generate API docs from schemas\n",
    "\n",
    "### Production Considerations\n",
    "\n",
    "1. **Performance**: Profile validation overhead\n",
    "2. **Memory Usage**: Be mindful of large object graphs\n",
    "3. **Backward Compatibility**: Plan for schema evolution\n",
    "4. **Testing**: Comprehensive validation testing\n",
    "5. **Monitoring**: Track validation errors in production\n",
    "\n",
    "## Use Cases for Structured Output\n",
    "\n",
    "### Data Extraction\n",
    "- **Contact Information**: Extract from emails, documents\n",
    "- **Financial Data**: Parse financial statements, reports\n",
    "- **Research Papers**: Analyze and structure academic content\n",
    "- **Legal Documents**: Extract key terms, clauses\n",
    "\n",
    "### Content Generation\n",
    "- **Documentation**: Generate structured technical docs\n",
    "- **Reports**: Create consistent business reports\n",
    "- **Analysis**: Produce standardized analysis results\n",
    "- **Summaries**: Generate structured content summaries\n",
    "\n",
    "### System Integration\n",
    "- **Database Population**: Direct insertion of structured data\n",
    "- **API Responses**: Consistent API output formats\n",
    "- **Message Queues**: Structured message passing\n",
    "- **Configuration**: Generate system configuration files\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Structured output with Pydantic provides:\n",
    "- **Data Quality**: Validation ensures clean, consistent data\n",
    "- **Type Safety**: Catch errors early in development\n",
    "- **Integration**: Easy connection to databases and APIs\n",
    "- **Documentation**: Self-documenting data structures\n",
    "- **Maintainability**: Clear contracts between system components\n",
    "\n",
    "This approach transforms agent responses from unpredictable text into reliable, structured data that can power robust applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}