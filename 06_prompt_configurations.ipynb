{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Three Methods of Prompt Configuration\n",
    "\n",
    "This notebook demonstrates different approaches to configuring agent prompts, from simple strings to dynamic, context-aware prompts.\n",
    "\n",
    "## Key Concepts\n",
    "- **Method 1**: String Prompt (simplest)\n",
    "- **Method 2**: SystemMessage (structured)\n",
    "- **Method 3**: Callable/Dynamic Prompt (advanced)\n",
    "\n",
    "## When to Use Each Method\n",
    "- **String**: Simple, static agents\n",
    "- **SystemMessage**: Production chat agents\n",
    "- **Callable**: Adaptive, personalized agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Make sure you have the required packages installed:\n",
    "\n",
    "```bash\n",
    "pip install langchain langchain-community langchain-core langgraph pydantic\n",
    "ollama pull qwen3\n",
    "ollama serve\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.agents import create_agent\n",
    "from langchain_core.messages import SystemMessage\n",
    "import tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Simple String Prompt\n",
    "\n",
    "The simplest approach - direct string instruction to the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Method 1: Simple String Prompt ===\")\n",
    "\n",
    "# Create model instance\n",
    "model = ChatOllama(model=\"qwen3\")\n",
    "\n",
    "# Method 1: String prompt (simplest)\n",
    "agent1 = create_agent(\n",
    "    model,\n",
    "    [tools.helper_tool],\n",
    "    prompt=\"You are a helpful assistant. Be concise and accurate in your responses.\"\n",
    ")\n",
    "\n",
    "print(\"âœ“ Agent 1 created with string prompt\")\n",
    "print(\"  Characteristics:\")\n",
    "print(\"  - Direct string instruction\")\n",
    "print(\"  - Simple and readable\")\n",
    "print(\"  - Good for basic use cases\")\n",
    "print(\"  - Easy to modify\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: SystemMessage Prompt\n",
    "\n",
    "Using LangChain's SystemMessage class for more structured prompt handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Method 2: SystemMessage Prompt ===\")\n",
    "\n",
    "# Method 2: SystemMessage prompt (structured)\n",
    "agent2 = create_agent(\n",
    "    model,\n",
    "    [tools.helper_tool],\n",
    "    prompt=SystemMessage(\n",
    "        content=\"You are a research assistant. Always cite your sources and provide detailed explanations.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"âœ“ Agent 2 created with SystemMessage prompt\")\n",
    "print(\"  Characteristics:\")\n",
    "print(\"  - Structured message object\")\n",
    "print(\"  - Better integration with chat models\")\n",
    "print(\"  - More explicit about message type\")\n",
    "print(\"  - Professional for production use\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3: Dynamic Callable Prompt\n",
    "\n",
    "A function that generates prompts based on state - the most flexible approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Method 3: Dynamic Callable Prompt ===\")\n",
    "\n",
    "# Method 3: Callable/Dynamic prompt (most flexible)\n",
    "def dynamic_prompt(state):\n",
    "    \"\"\"Generate prompt based on user type and context.\"\"\"\n",
    "    user_type = state.get(\"user_type\", \"standard\")\n",
    "    \n",
    "    if user_type == \"expert\":\n",
    "        system_msg = SystemMessage(\n",
    "            content=\"Provide detailed technical responses with code examples and advanced concepts.\"\n",
    "        )\n",
    "    elif user_type == \"beginner\":\n",
    "        system_msg = SystemMessage(\n",
    "            content=\"Provide simple, clear explanations suitable for beginners. Use analogies and avoid jargon.\"\n",
    "        )\n",
    "    else:  # standard\n",
    "        system_msg = SystemMessage(\n",
    "            content=\"Provide balanced explanations that are informative but accessible.\"\n",
    "        )\n",
    "    \n",
    "    return [system_msg] + state[\"messages\"]\n",
    "\n",
    "agent3 = create_agent(model, [tools.helper_tool], prompt=dynamic_prompt)\n",
    "\n",
    "print(\"âœ“ Agent 3 created with dynamic callable prompt\")\n",
    "print(\"  Characteristics:\")\n",
    "print(\"  - Adapts to user context\")\n",
    "print(\"  - Personalized responses\")\n",
    "print(\"  - Most flexible approach\")\n",
    "print(\"  - Perfect for adaptive systems\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing All Three Agents\n",
    "\n",
    "Let's test all agents with the same question to see their different behaviors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test question for all agents\n",
    "test_question = \"Help me understand artificial intelligence\"\n",
    "\n",
    "print(f\"Testing all agents with: '{test_question}'\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Test Agent 1 (String prompt)\n",
    "print(\"\\n=== Agent 1 Response (String Prompt) ===\")\n",
    "print(\"Expected: Concise and accurate response\")\n",
    "try:\n",
    "    result1 = agent1.invoke({\"messages\": test_question})\n",
    "    print(f\"Response: {result1['messages'][-1].content}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# Test Agent 2 (SystemMessage prompt)\n",
    "print(\"\\n=== Agent 2 Response (SystemMessage Prompt) ===\")\n",
    "print(\"Expected: Detailed explanation with research focus\")\n",
    "try:\n",
    "    result2 = agent2.invoke({\"messages\": test_question})\n",
    "    print(f\"Response: {result2['messages'][-1].content}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Dynamic Prompt with Different User Types\n",
    "\n",
    "The dynamic prompt agent can adapt based on user context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Agent 3 Responses (Dynamic Prompt) ===\")\n",
    "\n",
    "# Test with expert mode\n",
    "print(\"\\n--- Expert Mode ---\")\n",
    "print(\"Expected: Technical response with advanced concepts\")\n",
    "try:\n",
    "    result3_expert = agent3.invoke({\n",
    "        \"messages\": test_question,\n",
    "        \"user_type\": \"expert\"\n",
    "    })\n",
    "    print(f\"Response: {result3_expert['messages'][-1].content}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# Test with beginner mode\n",
    "print(\"\\n--- Beginner Mode ---\")\n",
    "print(\"Expected: Simple explanation with analogies\")\n",
    "try:\n",
    "    result3_beginner = agent3.invoke({\n",
    "        \"messages\": test_question,\n",
    "        \"user_type\": \"beginner\"\n",
    "    })\n",
    "    print(f\"Response: {result3_beginner['messages'][-1].content}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# Test with standard mode (default)\n",
    "print(\"\\n--- Standard Mode ---\")\n",
    "print(\"Expected: Balanced explanation\")\n",
    "try:\n",
    "    result3_standard = agent3.invoke({\n",
    "        \"messages\": test_question,\n",
    "        \"user_type\": \"standard\"\n",
    "    })\n",
    "    print(f\"Response: {result3_standard['messages'][-1].content}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Notice how each agent responds differently based on its prompt configuration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Dynamic Prompt Examples\n",
    "\n",
    "Let's explore more sophisticated dynamic prompt patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Advanced Dynamic Prompt Examples ===\")\n",
    "\n",
    "# Context-aware prompt that considers conversation history\n",
    "def context_aware_prompt(state):\n",
    "    \"\"\"Prompt that adapts based on conversation context.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    message_count = len(messages)\n",
    "    \n",
    "    # Analyze conversation length\n",
    "    if message_count > 10:\n",
    "        style = \"You are now in deep conversation mode. Provide comprehensive, detailed responses.\"\n",
    "    elif message_count > 5:\n",
    "        style = \"Continue the conversation with informative but concise responses.\"\n",
    "    else:\n",
    "        style = \"You are starting a new conversation. Be welcoming and helpful.\"\n",
    "    \n",
    "    # Check for specific topics in recent messages\n",
    "    recent_content = \" \".join(str(msg.content) for msg in messages[-3:] if hasattr(msg, 'content'))\n",
    "    \n",
    "    if \"technical\" in recent_content.lower():\n",
    "        style += \" Focus on technical accuracy and provide examples.\"\n",
    "    elif \"simple\" in recent_content.lower() or \"explain\" in recent_content.lower():\n",
    "        style += \" Keep explanations simple and clear.\"\n",
    "    \n",
    "    return [SystemMessage(content=style)] + messages\n",
    "\n",
    "# Time-based prompt\n",
    "def time_based_prompt(state):\n",
    "    \"\"\"Prompt that changes based on time of day (simulated).\"\"\"\n",
    "    import datetime\n",
    "    hour = datetime.datetime.now().hour\n",
    "    \n",
    "    if 6 <= hour < 12:\n",
    "        greeting = \"Good morning! I'm here to help you start your day productively.\"\n",
    "    elif 12 <= hour < 18:\n",
    "        greeting = \"Good afternoon! How can I assist you today?\"\n",
    "    else:\n",
    "        greeting = \"Good evening! I'm here to help with any questions you have.\"\n",
    "    \n",
    "    return [SystemMessage(content=greeting)] + state[\"messages\"]\n",
    "\n",
    "# Domain-specific prompt\n",
    "def domain_prompt(state):\n",
    "    \"\"\"Prompt that adapts based on detected domain.\"\"\"\n",
    "    content = \" \".join(str(msg.content) for msg in state[\"messages\"] if hasattr(msg, 'content')).lower()\n",
    "    \n",
    "    if any(word in content for word in [\"code\", \"programming\", \"software\", \"algorithm\"]):\n",
    "        domain_style = \"You are a programming assistant. Provide code examples and technical guidance.\"\n",
    "    elif any(word in content for word in [\"business\", \"marketing\", \"strategy\", \"sales\"]):\n",
    "        domain_style = \"You are a business consultant. Focus on practical business advice and strategies.\"\n",
    "    elif any(word in content for word in [\"science\", \"research\", \"study\", \"experiment\"]):\n",
    "        domain_style = \"You are a scientific advisor. Provide evidence-based information and cite sources.\"\n",
    "    else:\n",
    "        domain_style = \"You are a general assistant. Provide helpful and accurate information.\"\n",
    "    \n",
    "    return [SystemMessage(content=domain_style)] + state[\"messages\"]\n",
    "\n",
    "print(\"âœ“ Advanced prompt functions defined:\")\n",
    "print(\"  - context_aware_prompt: Adapts to conversation length and topics\")\n",
    "print(\"  - time_based_prompt: Changes greeting based on time of day\")\n",
    "print(\"  - domain_prompt: Detects domain and adjusts expertise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Agents with Advanced Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agents with advanced prompt functions\n",
    "context_agent = create_agent(model, [tools.helper_tool], prompt=context_aware_prompt)\n",
    "time_agent = create_agent(model, [tools.helper_tool], prompt=time_based_prompt)\n",
    "domain_agent = create_agent(model, [tools.helper_tool], prompt=domain_prompt)\n",
    "\n",
    "print(\"âœ“ Advanced agents created\")\n",
    "\n",
    "# Test domain detection\n",
    "print(\"\\n=== Testing Domain Detection ===\")\n",
    "\n",
    "domain_tests = [\n",
    "    (\"Help me write a Python function\", \"Programming\"),\n",
    "    (\"What's a good marketing strategy?\", \"Business\"),\n",
    "    (\"Explain quantum physics research\", \"Science\"),\n",
    "    (\"What's the weather like?\", \"General\")\n",
    "]\n",
    "\n",
    "for query, expected_domain in domain_tests:\n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    print(f\"Expected domain: {expected_domain}\")\n",
    "    try:\n",
    "        result = domain_agent.invoke({\"messages\": query})\n",
    "        print(f\"Response type: Detected domain correctly\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Template Patterns\n",
    "\n",
    "Common patterns for building dynamic prompts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Prompt Template Patterns ===\")\n",
    "\n",
    "# Template-based prompt builder\n",
    "class PromptBuilder:\n",
    "    \"\"\"Builder pattern for constructing dynamic prompts.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.base_prompt = \"You are a helpful assistant.\"\n",
    "        self.personality_traits = []\n",
    "        self.constraints = []\n",
    "        self.context_rules = []\n",
    "    \n",
    "    def set_personality(self, trait):\n",
    "        \"\"\"Add personality trait.\"\"\"\n",
    "        self.personality_traits.append(trait)\n",
    "        return self\n",
    "    \n",
    "    def add_constraint(self, constraint):\n",
    "        \"\"\"Add behavioral constraint.\"\"\"\n",
    "        self.constraints.append(constraint)\n",
    "        return self\n",
    "    \n",
    "    def add_context_rule(self, rule):\n",
    "        \"\"\"Add context-specific rule.\"\"\"\n",
    "        self.context_rules.append(rule)\n",
    "        return self\n",
    "    \n",
    "    def build(self, state):\n",
    "        \"\"\"Build the final prompt based on state.\"\"\"\n",
    "        parts = [self.base_prompt]\n",
    "        \n",
    "        if self.personality_traits:\n",
    "            parts.append(f\"Personality: {', '.join(self.personality_traits)}.\")\n",
    "        \n",
    "        if self.constraints:\n",
    "            parts.append(f\"Constraints: {' '.join(self.constraints)}\")\n",
    "        \n",
    "        if self.context_rules:\n",
    "            parts.append(f\"Context rules: {' '.join(self.context_rules)}\")\n",
    "        \n",
    "        final_prompt = \" \".join(parts)\n",
    "        return [SystemMessage(content=final_prompt)] + state[\"messages\"]\n",
    "\n",
    "# Example usage\n",
    "friendly_prompt = (PromptBuilder()\n",
    "                   .set_personality(\"friendly\")\n",
    "                   .set_personality(\"encouraging\")\n",
    "                   .add_constraint(\"Keep responses under 100 words.\")\n",
    "                   .add_context_rule(\"If user seems frustrated, be extra supportive.\"))\n",
    "\n",
    "technical_prompt = (PromptBuilder()\n",
    "                    .set_personality(\"precise\")\n",
    "                    .set_personality(\"analytical\")\n",
    "                    .add_constraint(\"Always provide examples.\")\n",
    "                    .add_constraint(\"Cite sources when possible.\")\n",
    "                    .add_context_rule(\"For code questions, include working examples.\"))\n",
    "\n",
    "print(\"âœ“ Prompt builder pattern implemented\")\n",
    "print(\"  - Modular prompt construction\")\n",
    "print(\"  - Reusable prompt components\")\n",
    "print(\"  - Easy to maintain and extend\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Prompt Builder Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agents with built prompts\n",
    "friendly_agent = create_agent(model, [tools.helper_tool], prompt=friendly_prompt.build)\n",
    "technical_agent = create_agent(model, [tools.helper_tool], prompt=technical_prompt.build)\n",
    "\n",
    "print(\"=== Testing Prompt Builder Agents ===\")\n",
    "\n",
    "test_query = \"Help me understand machine learning\"\n",
    "\n",
    "print(f\"\\nTest query: '{test_query}'\")\n",
    "\n",
    "# Test friendly agent\n",
    "print(\"\\n--- Friendly Agent ---\")\n",
    "print(\"Expected: Encouraging, supportive response under 100 words\")\n",
    "try:\n",
    "    friendly_result = friendly_agent.invoke({\"messages\": test_query})\n",
    "    response = friendly_result['messages'][-1].content\n",
    "    print(f\"Response ({len(response.split())} words): {response}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# Test technical agent\n",
    "print(\"\\n--- Technical Agent ---\")\n",
    "print(\"Expected: Precise, analytical response with examples\")\n",
    "try:\n",
    "    technical_result = technical_agent.invoke({\"messages\": test_query})\n",
    "    response = technical_result['messages'][-1].content\n",
    "    print(f\"Response: {response}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices Summary\n",
    "\n",
    "### Method Selection Guide\n",
    "\n",
    "#### Use String Prompts When:\n",
    "- **Prototyping** and quick experimentation\n",
    "- **Simple, static** instructions\n",
    "- **Learning** LangChain basics\n",
    "- **Single-purpose** agents\n",
    "\n",
    "#### Use SystemMessage When:\n",
    "- **Production** chat applications\n",
    "- **Structured** message handling\n",
    "- **Better integration** with chat models\n",
    "- **Professional** applications\n",
    "\n",
    "#### Use Dynamic Prompts When:\n",
    "- **Personalization** is required\n",
    "- **Context-aware** responses needed\n",
    "- **Adaptive behavior** based on state\n",
    "- **Complex** decision logic\n",
    "\n",
    "### Dynamic Prompt Patterns\n",
    "\n",
    "1. **User Type Adaptation**\n",
    "   ```python\n",
    "   def user_prompt(state):\n",
    "       user_type = state.get(\"user_type\", \"standard\")\n",
    "       # Adjust based on expertise level\n",
    "   ```\n",
    "\n",
    "2. **Context History Analysis**\n",
    "   ```python\n",
    "   def context_prompt(state):\n",
    "       recent_topics = analyze_recent_messages(state[\"messages\"])\n",
    "       # Adapt based on conversation topics\n",
    "   ```\n",
    "\n",
    "3. **Domain Detection**\n",
    "   ```python\n",
    "   def domain_prompt(state):\n",
    "       domain = detect_domain(state[\"messages\"])\n",
    "       # Switch expertise based on detected domain\n",
    "   ```\n",
    "\n",
    "4. **Time/Session Context**\n",
    "   ```python\n",
    "   def session_prompt(state):\n",
    "       session_info = state.get(\"session_info\", {})\n",
    "       # Adapt based on session metadata\n",
    "   ```\n",
    "\n",
    "### Design Principles\n",
    "\n",
    "1. **Progressive Enhancement**: Start simple, add complexity as needed\n",
    "2. **Separation of Concerns**: Keep prompt logic separate from business logic\n",
    "3. **Testability**: Make dynamic prompts easy to test with different inputs\n",
    "4. **Maintainability**: Use builder patterns for complex prompt construction\n",
    "5. **Performance**: Cache expensive prompt computations when possible\n",
    "\n",
    "### Common Pitfalls\n",
    "\n",
    "1. **Over-complexity**: Don't make prompts unnecessarily complex\n",
    "2. **Inconsistent Behavior**: Ensure dynamic prompts produce consistent results\n",
    "3. **Poor Error Handling**: Handle edge cases in dynamic prompt functions\n",
    "4. **Lack of Fallbacks**: Always have default behavior for unexpected states\n",
    "5. **Prompt Injection**: Validate and sanitize dynamic content\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Prompt configuration is crucial for agent behavior:\n",
    "- **String prompts** are perfect for getting started\n",
    "- **SystemMessage** provides structure for production use\n",
    "- **Dynamic prompts** enable sophisticated, adaptive agents\n",
    "- **Builder patterns** help manage complex prompt logic\n",
    "- **Context awareness** dramatically improves user experience\n",
    "\n",
    "Choose the method that best fits your use case, and don't be afraid to start simple and evolve your approach as your requirements grow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}