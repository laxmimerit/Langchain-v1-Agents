{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Model Selection - Minimal Implementation\n",
    "\n",
    "This notebook demonstrates intelligent model selection based on content analysis, similar to `agents.py:example_4_advanced_model_selection()`.\n",
    "\n",
    "## Key Features\n",
    "- **Content Analysis**: Detects complexity keywords automatically\n",
    "- **Length-based Selection**: Long conversations trigger better models  \n",
    "- **Smart Switching**: Minimal overhead, maximum efficiency\n",
    "\n",
    "## Selection Logic\n",
    "- Use GPT-OSS if: total chars > 3000 OR contains complexity keywords OR message count > 8\n",
    "- Otherwise: Use Qwen3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "```bash\n",
    "pip install langchain langchain-community langchain-core langgraph\n",
    "ollama pull qwen3\n",
    "ollama pull gpt-oss\n",
    "ollama serve\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "from typing import TypedDict, Dict, Any, List\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langgraph.runtime import Runtime\n",
    "import tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intelligent Model Selection Function\n",
    "\n",
    "Based on `agents.py:example_4_advanced_model_selection()` - analyzes content complexity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intelligent_model_select(state: AgentState, runtime: Runtime) -> ChatOllama:\n",
    "    \"\"\"Intelligent model selection based on multiple factors.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    message_count = len(messages)\n",
    "    \n",
    "    # Factor 1: Calculate total content length\n",
    "    total_length = sum(\n",
    "        len(str(msg.content)) \n",
    "        for msg in messages \n",
    "        if hasattr(msg, 'content') and msg.content\n",
    "    )\n",
    "    \n",
    "    # Factor 2: Check for complexity keywords\n",
    "    complex_keywords = [\"analysis\", \"research\", \"detailed\", \"comprehensive\", \"complex\", \"strategy\"]\n",
    "    has_complex_content = any(\n",
    "        keyword in str(msg.content).lower() \n",
    "        for msg in messages \n",
    "        for keyword in complex_keywords \n",
    "        if hasattr(msg, 'content') and msg.content\n",
    "    )\n",
    "    \n",
    "    # Multi-factor decision logic\n",
    "    if total_length > 3000 or has_complex_content or message_count > 8:\n",
    "        print(f\"GPT-OSS: {message_count} msgs, {total_length} chars, keywords: {has_complex_content}\")\n",
    "        return ChatOllama(model=\"gpt-oss\", temperature=0.0, num_predict=2500).bind_tools([tools.web_search])\n",
    "    else:\n",
    "        print(f\"Qwen3: {message_count} msgs, {total_length} chars, keywords: {has_complex_content}\")\n",
    "        return ChatOllama(model=\"qwen3\", temperature=0.1, num_predict=1000).bind_tools([tools.web_search])\n",
    "\n",
    "# Create agent with intelligent model selection\n",
    "agent = create_agent(intelligent_model_select, tools=[tools.web_search])\n",
    "print(\"✓ Smart agent created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: Simple Query → Qwen3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = agent.invoke({\"messages\": \"Hello there\"})\n",
    "print(\"✓ Simple query processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: Complex Keywords → GPT-OSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_query = \"I need comprehensive analysis and detailed research on AI strategies\"\n",
    "result2 = agent.invoke({\"messages\": complex_query})\n",
    "print(\"✓ Complex keywords triggered GPT-OSS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3: Long Content → GPT-OSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create long message (>3000 chars)\n",
    "long_message = \"Please help me understand this topic. \" * 80  \n",
    "result3 = agent.invoke({\"messages\": long_message})\n",
    "print(f\"✓ Long content ({len(long_message)} chars) triggered GPT-OSS\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-v1-agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
