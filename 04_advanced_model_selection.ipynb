{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sophisticated Content-Aware Model Selection\n",
    "\n",
    "This notebook demonstrates an advanced approach that analyzes not just message count, but also content complexity, conversation length, and context clues.\n",
    "\n",
    "## Key Concepts\n",
    "- **Multi-Factor Analysis**: Content complexity, length, and message count\n",
    "- **Keyword Detection**: Automatic complexity recognition\n",
    "- **Smart Decision Making**: Context-aware model selection\n",
    "\n",
    "## Selection Factors\n",
    "1. **Keyword Analysis**: Looks for words like \"analysis\", \"research\", \"comprehensive\"\n",
    "2. **Content Length**: Long conversations often need better reasoning\n",
    "3. **Message Count**: Many exchanges suggest complex discussion\n",
    "\n",
    "## Algorithm Logic\n",
    "Use GPT-OSS if ANY of these conditions are true:\n",
    "- Total characters > 3000\n",
    "- Contains complexity keywords\n",
    "- Message count > 8\n",
    "\n",
    "Otherwise use Qwen3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Make sure you have the required packages installed and both models available:\n",
    "\n",
    "```bash\n",
    "pip install langchain langchain-community langchain-core langgraph pydantic\n",
    "ollama pull qwen3\n",
    "ollama pull gpt-oss\n",
    "ollama serve\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "from typing import TypedDict, Dict, Any, List\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langgraph.runtime import Runtime\n",
    "import tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intelligent Model Selection Function\n",
    "\n",
    "This function analyzes multiple factors to make smart decisions about which model to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intelligent model selection function defined!\n",
      "Factors: content length, complexity keywords, message count\n"
     ]
    }
   ],
   "source": [
    "# Define tool list\n",
    "tool_list = [tools.web_search]\n",
    "\n",
    "def intelligent_model_select(state: AgentState, runtime: Runtime) -> ChatOllama:\n",
    "    \"\"\"Intelligent model selection based on multiple factors.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    message_count = len(messages)\n",
    "    \n",
    "    # Factor 1: Calculate total content length\n",
    "    total_length = sum(\n",
    "        len(str(msg.content)) \n",
    "        for msg in messages \n",
    "        if hasattr(msg, 'content') and msg.content\n",
    "    )\n",
    "    \n",
    "    # Factor 2: Check for complexity keywords\n",
    "    complex_keywords = [\n",
    "        \"analysis\", \"research\", \"detailed\", \"comprehensive\", \n",
    "        \"complex\", \"strategy\", \"evaluate\", \"compare\",\n",
    "        \"investigate\", \"thorough\", \"in-depth\", \"sophisticated\"\n",
    "    ]\n",
    "    \n",
    "    has_complex_content = any(\n",
    "        keyword in str(msg.content).lower() \n",
    "        for msg in messages \n",
    "        for keyword in complex_keywords \n",
    "        if hasattr(msg, 'content') and msg.content\n",
    "    )\n",
    "    \n",
    "    # Multi-factor decision logic\n",
    "    if total_length > 3000 or has_complex_content or message_count > 8:\n",
    "        print(f\"  GPT-OSS selected: {message_count} msgs, {total_length} chars, complex_keywords: {has_complex_content}\")\n",
    "        return ChatOllama(\n",
    "            model=\"gpt-oss\", \n",
    "            temperature=0.0, \n",
    "            num_predict=2500\n",
    "        ).bind_tools(tool_list)\n",
    "    else:\n",
    "        print(f\"  Qwen3 selected: {message_count} msgs, {total_length} chars, complex_keywords: {has_complex_content}\")\n",
    "        return ChatOllama(\n",
    "            model=\"qwen3\", \n",
    "            temperature=0.1, \n",
    "            num_predict=1000\n",
    "        ).bind_tools(tool_list)\n",
    "\n",
    "print(\"Intelligent model selection function defined!\")\n",
    "print(\"Factors: content length, complexity keywords, message count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Smart Agent\n",
    "\n",
    "Create an agent that uses our intelligent model selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smart agent created successfully!\n",
      "This agent analyzes content complexity to choose the best model\n"
     ]
    }
   ],
   "source": [
    "# Create agent with intelligent model selection\n",
    "agent = create_agent(intelligent_model_select, tools=tool_list)\n",
    "\n",
    "print(\"Smart agent created successfully!\")\n",
    "print(\"This agent analyzes content complexity to choose the best model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: Simple Query (Should Use Qwen3)\n",
    "\n",
    "Let's test with a simple query that should trigger Qwen3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing Simple Query (Should Use Qwen3) ===\n",
      "  Qwen3 selected: 1 msgs, 11 chars, complex_keywords: False\n",
      "\n",
      "Simple query result processed successfully\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Testing Simple Query (Should Use Qwen3) ===\")\n",
    "\n",
    "result1 = agent.invoke({\n",
    "    \"messages\": \"Hello there\"\n",
    "})\n",
    "\n",
    "print(f\"\\nSimple query result processed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: Complex Query with Keywords (Should Use GPT-OSS)\n",
    "\n",
    "Now let's test with a query containing complexity keywords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing Complex Query with Keywords (Should Use GPT-OSS) ===\n",
      "  GPT-OSS selected: 1 msgs, 91 chars, complex_keywords: True\n",
      "  GPT-OSS selected: 3 msgs, 1677 chars, complex_keywords: True\n",
      "  GPT-OSS selected: 5 msgs, 3310 chars, complex_keywords: True\n",
      "  GPT-OSS selected: 7 msgs, 4847 chars, complex_keywords: True\n",
      "\n",
      "Notice: Complex keywords triggered GPT-OSS even for a single message\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Testing Complex Query with Keywords (Should Use GPT-OSS) ===\")\n",
    "\n",
    "complex_query = \"I need a comprehensive analysis and detailed research on market strategies for AI companies\"\n",
    "\n",
    "result2 = agent.invoke({\n",
    "    \"messages\": complex_query\n",
    "})\n",
    "\n",
    "print(\"\\nNotice: Complex keywords triggered GPT-OSS even for a single message\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3: Long Content (Should Use GPT-OSS)\n",
    "\n",
    "Test with a message that exceeds the character threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing Long Content (Should Use GPT-OSS) ===\n",
      "  GPT-OSS selected: 1 msgs, 7600 chars, complex_keywords: False\n",
      "\n",
      "Long content (>7600 chars) triggered GPT-OSS\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Testing Long Content (Should Use GPT-OSS) ===\")\n",
    "\n",
    "# Create a long message that exceeds 3000 characters\n",
    "long_message = \"Please help me understand this topic. \" * 200  # Creates a long message\n",
    "\n",
    "result3 = agent.invoke({\n",
    "    \"messages\": long_message\n",
    "})\n",
    "\n",
    "print(f\"\\nLong content (>{len(long_message)} chars) triggered GPT-OSS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-World Benefits\n",
    "\n",
    "### Immediate Complex Query Handling\n",
    "- A single complex question immediately gets the better model\n",
    "- No need to wait for conversation to grow\n",
    "- Better user experience for demanding tasks\n",
    "\n",
    "### Efficient Resource Usage\n",
    "- Long simple conversations don't waste expensive model usage\n",
    "- Smart detection prevents unnecessary upgrades\n",
    "- Cost optimization with quality assurance\n",
    "\n",
    "### Context-Aware Decisions\n",
    "- Content analysis provides better context than just message count\n",
    "- Keyword detection catches complexity early\n",
    "- Multi-factor analysis reduces false positives/negatives\n",
    "\n",
    "## Customization Examples\n",
    "\n",
    "### Industry-Specific Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Legal industry keywords\n",
    "legal_keywords = [\n",
    "    \"contract\", \"litigation\", \"compliance\", \"regulation\",\n",
    "    \"precedent\", \"statute\", \"brief\", \"discovery\"\n",
    "]\n",
    "\n",
    "# Example: Medical industry keywords\n",
    "medical_keywords = [\n",
    "    \"diagnosis\", \"treatment\", \"symptoms\", \"pathology\",\n",
    "    \"clinical\", \"therapeutic\", \"pharmaceutical\", \"protocol\"\n",
    "]\n",
    "\n",
    "# Example: Financial industry keywords\n",
    "financial_keywords = [\n",
    "    \"portfolio\", \"investment\", \"risk\", \"valuation\",\n",
    "    \"derivatives\", \"compliance\", \"audit\", \"forecast\"\n",
    "]\n",
    "\n",
    "print(\"Industry-specific keyword sets:\")\n",
    "print(f\"Legal: {', '.join(legal_keywords[:4])}...\")\n",
    "print(f\"Medical: {', '.join(medical_keywords[:4])}...\")\n",
    "print(f\"Financial: {', '.join(financial_keywords[:4])}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_model_selector(state: AgentState, runtime: Runtime) -> ChatOllama:\n",
    "    \"\"\"Example of more sophisticated selection logic.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # Calculate various metrics\n",
    "    message_count = len(messages)\n",
    "    total_length = sum(len(str(msg.content)) for msg in messages if hasattr(msg, 'content') and msg.content)\n",
    "    avg_message_length = total_length / message_count if message_count > 0 else 0\n",
    "    \n",
    "    # Advanced keyword categories\n",
    "    complexity_keywords = [\"analysis\", \"research\", \"comprehensive\"]\n",
    "    urgency_keywords = [\"urgent\", \"immediate\", \"asap\", \"critical\"]\n",
    "    technical_keywords = [\"algorithm\", \"implementation\", \"architecture\", \"optimization\"]\n",
    "    \n",
    "    # Check for different types of complexity\n",
    "    content_text = \" \".join(str(msg.content) for msg in messages if hasattr(msg, 'content') and msg.content).lower()\n",
    "    \n",
    "    has_complexity = any(kw in content_text for kw in complexity_keywords)\n",
    "    has_urgency = any(kw in content_text for kw in urgency_keywords)\n",
    "    has_technical = any(kw in content_text for kw in technical_keywords)\n",
    "    \n",
    "    # Scoring system\n",
    "    score = 0\n",
    "    score += message_count * 0.5  # Each message adds 0.5 points\n",
    "    score += total_length / 1000  # Each 1000 chars adds 1 point\n",
    "    score += 3 if has_complexity else 0  # Complexity adds 3 points\n",
    "    score += 2 if has_technical else 0   # Technical adds 2 points\n",
    "    score += 1 if has_urgency else 0     # Urgency adds 1 point\n",
    "    \n",
    "    # Decision based on score\n",
    "    if score >= 5.0:  # Threshold for GPT-OSS\n",
    "        print(f\"  GPT-OSS selected (score: {score:.1f})\")\n",
    "        return ChatOllama(model=\"gpt-oss\", temperature=0.0, num_predict=2500).bind_tools(tool_list)\n",
    "    else:\n",
    "        print(f\"  Qwen3 selected (score: {score:.1f})\")\n",
    "        return ChatOllama(model=\"qwen3\", temperature=0.1, num_predict=1000).bind_tools(tool_list)\n",
    "\n",
    "print(\"Advanced scoring-based model selector defined!\")\n",
    "print(\"Uses weighted scoring: messages + length + keyword categories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices\n",
    "\n",
    "### 1. Monitor and Adjust\n",
    "- Track model selection decisions\n",
    "- Analyze which factors trigger switches most often\n",
    "- Adjust thresholds based on usage patterns\n",
    "\n",
    "### 2. Domain-Specific Tuning\n",
    "- Create keyword sets for your specific domain\n",
    "- Adjust character thresholds based on typical content\n",
    "- Consider user behavior patterns\n",
    "\n",
    "### 3. Performance Optimization\n",
    "- Cache keyword lookups for frequently used terms\n",
    "- Use efficient string matching algorithms\n",
    "- Consider preprocessing for better performance\n",
    "\n",
    "### 4. User Experience\n",
    "- Provide feedback about model switches (if appropriate)\n",
    "- Ensure smooth transitions between models\n",
    "- Handle edge cases gracefully\n",
    "\n",
    "### 5. Cost Management\n",
    "- Monitor actual cost savings vs. performance gains\n",
    "- Track false positives (unnecessary upgrades)\n",
    "- Balance cost optimization with user satisfaction\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This sophisticated approach provides:\n",
    "- **Better accuracy** in model selection\n",
    "- **Immediate response** to complex queries\n",
    "- **Cost efficiency** with quality assurance\n",
    "- **Flexibility** for domain-specific customization\n",
    "- **Scalability** for various use cases"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-v1-agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
