{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Advanced Model Selection - Minimal Implementation\n\nThis notebook demonstrates intelligent model selection based on content analysis, similar to `agents.py:example_4_advanced_model_selection()`.\n\n## Key Features\n- **Content Analysis**: Detects complexity keywords automatically\n- **Length-based Selection**: Long conversations trigger better models  \n- **Smart Switching**: Minimal overhead, maximum efficiency\n\n## Selection Logic\n- Use GPT-OSS if: total chars > 3000 OR contains complexity keywords OR message count > 8\n- Otherwise: Use Qwen3"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Prerequisites\n\n```bash\npip install langchain langchain-community langchain-core langgraph\nollama pull qwen3\nollama pull gpt-oss\nollama serve\n```"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Import required modules\nfrom typing import TypedDict, Dict, Any, List\nfrom langchain_ollama import ChatOllama\nfrom langchain.agents import create_agent, AgentState\nfrom langgraph.runtime import Runtime\nimport tools"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Intelligent Model Selection Function\n\nBased on `agents.py:example_4_advanced_model_selection()` - analyzes content complexity:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def intelligent_model_select(state: AgentState, runtime: Runtime) -> ChatOllama:\n    \"\"\"Intelligent model selection based on multiple factors.\"\"\"\n    messages = state[\"messages\"]\n    message_count = len(messages)\n    \n    # Factor 1: Calculate total content length\n    total_length = sum(\n        len(str(msg.content)) \n        for msg in messages \n        if hasattr(msg, 'content') and msg.content\n    )\n    \n    # Factor 2: Check for complexity keywords\n    complex_keywords = [\"analysis\", \"research\", \"detailed\", \"comprehensive\", \"complex\", \"strategy\"]\n    has_complex_content = any(\n        keyword in str(msg.content).lower() \n        for msg in messages \n        for keyword in complex_keywords \n        if hasattr(msg, 'content') and msg.content\n    )\n    \n    # Multi-factor decision logic\n    if total_length > 3000 or has_complex_content or message_count > 8:\n        print(f\"GPT-OSS: {message_count} msgs, {total_length} chars, keywords: {has_complex_content}\")\n        return ChatOllama(model=\"gpt-oss\", temperature=0.0, num_predict=2500).bind_tools([tools.web_search])\n    else:\n        print(f\"Qwen3: {message_count} msgs, {total_length} chars, keywords: {has_complex_content}\")\n        return ChatOllama(model=\"qwen3\", temperature=0.1, num_predict=1000).bind_tools([tools.web_search])\n\n# Create agent with intelligent model selection\nagent = create_agent(intelligent_model_select, tools=[tools.web_search])\nprint(\"✓ Smart agent created!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Test 1: Simple Query → Qwen3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "result1 = agent.invoke({\"messages\": \"Hello there\"})\nprint(\"✓ Simple query processed\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Test 2: Complex Keywords → GPT-OSS"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "complex_query = \"I need comprehensive analysis and detailed research on AI strategies\"\nresult2 = agent.invoke({\"messages\": complex_query})\nprint(\"✓ Complex keywords triggered GPT-OSS\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Test 3: Long Content → GPT-OSS"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create long message (>3000 chars)\nlong_message = \"Please help me understand this topic. \" * 80  \nresult3 = agent.invoke({\"messages\": long_message})\nprint(f\"✓ Long content ({len(long_message)} chars) triggered GPT-OSS\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\nThis minimal implementation demonstrates:\n\n✅ **Smart Detection**: Keywords trigger better model immediately  \n✅ **Length Analysis**: Long conversations get appropriate resources  \n✅ **Cost Optimization**: Efficient model for simple tasks  \n✅ **Seamless Switching**: No manual intervention needed\n\nBased on `agents.py:217-257` but streamlined for practical use."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-World Benefits\n",
    "\n",
    "### Immediate Complex Query Handling\n",
    "- A single complex question immediately gets the better model\n",
    "- No need to wait for conversation to grow\n",
    "- Better user experience for demanding tasks\n",
    "\n",
    "### Efficient Resource Usage\n",
    "- Long simple conversations don't waste expensive model usage\n",
    "- Smart detection prevents unnecessary upgrades\n",
    "- Cost optimization with quality assurance\n",
    "\n",
    "### Context-Aware Decisions\n",
    "- Content analysis provides better context than just message count\n",
    "- Keyword detection catches complexity early\n",
    "- Multi-factor analysis reduces false positives/negatives\n",
    "\n",
    "## Customization Examples\n",
    "\n",
    "### Industry-Specific Keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Thresholds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-v1-agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}